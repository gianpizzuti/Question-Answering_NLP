{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# T5 - Question answering with indexing of answers"
      ],
      "metadata": {
        "id": "u6UbrHACaDMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we implement the pipeline for using [T5](https://github.com/google-research/text-to-text-transfer-transformer) (Text-To-Text Transfer Transformer) on the Medical Meadows Anki flashcards dataset. We will use the [flan-t5-large](https://huggingface.co/google/flan-t5-small). \\\n",
        "To perform the task we will:\n",
        "- encode all the answers in the dataset in embeddings, using\n",
        "[multi-qa-MiniLM-L6-cos-v1](https://huggingface.co/sentence-transformers/multi-qa-MiniLM-L6-cos-v1)\n",
        "- given a question of a user, first search for the most similar 5 question      (embeddings), then use these as context to answer."
      ],
      "metadata": {
        "id": "e4JYuwAlDv5K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0) Imports, loading datasets and models"
      ],
      "metadata": {
        "id": "Y0JDI3JZcNlM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIsoyf6RaAkF"
      },
      "outputs": [],
      "source": [
        "!pip -q install -U transformers sentence-transformers\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlpK2HGjaAkG"
      },
      "outputs": [],
      "source": [
        "dataset_filepath = './medical_meadow_wikidoc_medical_flashcards.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLmveMXFaAkH",
        "outputId": "62f04f34-919f-4abf-a374-c64251ac72ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved 33955 answers\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['Very low Mg2+ levels correspond to low PTH levels which in turn results in low Ca2+ levels.',\n",
              " 'Low estradiol production leads to genitourinary syndrome of menopause (atrophic vaginitis).',\n",
              " 'Low REM sleep latency and experiencing hallucinations/sleep paralysis suggests narcolepsy.',\n",
              " 'PTH-independent hypercalcemia, which can be caused by cancer, granulomatous disease, or vitamin D intoxication.',\n",
              " 'The level of anti-mÃ¼llerian hormone is directly related to ovarian reserve - a lower level indicates a lower ovarian reserve.',\n",
              " 'Low Mobility and bulging of TM is suggestive of Acute otitis media.',\n",
              " 'Low glucose and high C-peptide levels can be caused by an insulinoma or the use of sulfonylurea drugs.',\n",
              " 'Insulinoma or sulfonylurea drugs can cause low Glucose and high C-peptide levels.',\n",
              " 'Low Ejection fraction is commonly associated with systolic dysfunction.',\n",
              " 'Emphysema is associated with low DLCO.']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load dataset\n",
        "import json\n",
        "import gzip\n",
        "\n",
        "with open(dataset_filepath, \"r\") as f:\n",
        "    dataset = json.load(f)\n",
        "\n",
        "answers = []\n",
        "for data in dataset:\n",
        "    answers.append(data['output'])\n",
        "\n",
        "print(f\"Retrieved {len(answers)} answers\")\n",
        "answers[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLU0N94FaAkI",
        "outputId": "99966e06-1bc6-47c8-fa54-9e22b5ee599f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Leonardo\\Documents\\school\\nlp\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "c:\\Users\\Leonardo\\Documents\\school\\nlp\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Leonardo\\Documents\\school\\nlp\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Import models\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "\n",
        "# sentence-transformers model: It maps sentences & paragraphs to a 384 dimensional dense vector space and was designed for semantic search.\n",
        "# trained on 215M (question, answer) pairs from diverse sources\n",
        "semb_model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
        "\n",
        "# information-retrieval model: given a query, return all possible relevant passages related to it and sort them in decreasing order.\n",
        "xenc_model = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1) Compute embeddings\n",
        "We now embed all the answers in the dataset (checkpointing the results)."
      ],
      "metadata": {
        "id": "oUT8fBr5ccMI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApRe4r3paAkJ",
        "outputId": "2bdf400c-2468-4b9e-b93e-59d16058c38c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading embeddings cache\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "# Define hnswlib index path\n",
        "embeddings_cache_path = './qa_embeddings_cache.pkl'\n",
        "\n",
        "# Load cache if available\n",
        "if os.path.exists(embeddings_cache_path):\n",
        "    print('Loading embeddings cache')\n",
        "    with open(embeddings_cache_path, 'rb') as f:\n",
        "        corpus_embeddings = pickle.load(f)\n",
        "# Else compute embeddings\n",
        "else:\n",
        "    print('Computing embeddings')\n",
        "    corpus_embeddings = semb_model.encode(answers, convert_to_tensor=True, show_progress_bar=True)\n",
        "    # Save the index to a file for future loading\n",
        "    print(f'Saving index to: \\'{embeddings_cache_path}\\'')\n",
        "    with open(embeddings_cache_path, 'wb') as f:\n",
        "        pickle.dump(corpus_embeddings, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2) Index the answers\n"
      ],
      "metadata": {
        "id": "Z3VljPf_dqKr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0mPCegMaAkK",
        "outputId": "34667ec9-cd41-4332-9512-4b5490a5c816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading index...\n"
          ]
        }
      ],
      "source": [
        "!pip -q install hnswlib\n",
        "\n",
        "# Index embeddings\n",
        "import os\n",
        "import hnswlib\n",
        "\n",
        "# Create empty index\n",
        "index = hnswlib.Index(space='cosine', dim=384)\n",
        "\n",
        "# Define hnswlib index path\n",
        "index_path = './qa_hnswlib.index'\n",
        "\n",
        "# Load index if available\n",
        "if os.path.exists(index_path):\n",
        "    print('Loading index...')\n",
        "    index.load_index(index_path)\n",
        "# Else index data collection\n",
        "else:\n",
        "    # Initialise the index\n",
        "    print('Started creating HNSWLIB index')\n",
        "    index.init_index(max_elements=corpus_embeddings.size(0), ef_construction=400, M=64)\n",
        "    #  Compute the HNSWLIB index (it may take a while)\n",
        "    index.add_items(corpus_embeddings.cpu(), list(range(len(corpus_embeddings))))\n",
        "    # Save the index to a file for future loading\n",
        "    print(f'Saving index to: {index_path}')\n",
        "    index.save_index(index_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Loading model and tokenizer"
      ],
      "metadata": {
        "id": "689OHuJOd_b1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pn0LrTZaaAkL",
        "outputId": "adde6a19-b824-4fac-f2e1-5e533bb00917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from accelerate) (5.9.8)\n",
            "Requirement already satisfied: pyyaml in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (2024.3.1)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (2021.4.0)\n",
            "Requirement already satisfied: requests in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.10.0->accelerate) (2021.12.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub->accelerate) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\leonardo\\documents\\school\\nlp\\.venv\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "!pip -q install sentencepiece\n",
        "!pip install accelerate\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-large\", device_map=\"cuda\",) #torch_dtype=torch.bfloat16)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Define pipeline\n",
        "We now define the pipeline with the following steps:\n",
        "- retrieve the top k(=64) answers\n",
        "- re-rank these k answers\n",
        "- take the top 5 answers according to re-rank and join them together, creating the \"context\"\n",
        "- create the input to the T5 model concatenating question and context\n",
        "- tokenize the input\n",
        "- generate tokenized output\n",
        "- decode output"
      ],
      "metadata": {
        "id": "kbydZR9DeLdy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dkDssxvaAkM"
      },
      "outputs": [],
      "source": [
        "# Define the QA pipeline\n",
        "\n",
        "def qa_pipeline(\n",
        "    question,\n",
        "    n_best_answers=5,\n",
        "    similarity_model=semb_model,\n",
        "    embeddings_index=index,\n",
        "    re_ranking_model=xenc_model,\n",
        "    generative_model=model,\n",
        "    device=device\n",
        "):\n",
        "    if not question.endswith('?'):\n",
        "        question = question + '?'\n",
        "    # Embed question\n",
        "    question_embedding = semb_model.encode(question, convert_to_tensor=True)\n",
        "    # Search documents similar to question in index\n",
        "    corpus_ids, distances = index.knn_query(question_embedding.cpu(), k=64)\n",
        "    # Re-rank results\n",
        "    xenc_model_inputs = [(question, answers[idx]) for idx in corpus_ids[0]]\n",
        "    cross_scores = xenc_model.predict(xenc_model_inputs)\n",
        "    # Get best matching answers\n",
        "    top_answers_idx = np.argsort(-cross_scores)[:n_best_answers]\n",
        "    context = [answers[corpus_ids[0][idx]] for idx in top_answers_idx]\n",
        "    context = '\\n'.join(context)\n",
        "    # Encode input\n",
        "    input_text = f\"Given the following facts:\\n\\n{context}\\n\\nPlease answer the following question exhaustively, providing comprehensive explanation: {question}\"\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n",
        "    # Generate output\n",
        "    output_ids = model.generate(input_ids, max_new_tokens=64)\n",
        "    # Decode output\n",
        "    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "    # Return result\n",
        "    return f\"Facts:\\n\\n{context}\\n\\nQ: {question}\\n\\nA: {output_text}\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can test the model:"
      ],
      "metadata": {
        "id": "ZHdtOGMYfo-P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh3fV4syaAkM",
        "outputId": "897da1ea-523d-46ef-aff0-fa316dc0ce5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Facts:\n",
            "\n",
            "The most common endogenous cause of Cushing's syndrome is Cushing's disease, which is characterized by the presence of an ACTH-secreting pituitary adenoma. Cushing's syndrome is a rare disorder that occurs when the body is exposed to high levels of the hormone cortisol for an extended period. Cortisol is a hormone that is produced by the adrenal glands and plays a vital role in regulating metabolism, immune function, and stress response. When cortisol levels are too high, it can lead to a range of symptoms, including weight gain, muscle weakness, high blood pressure, and mood changes. Cushing's disease is responsible for around 70% of all cases of Cushing's syndrome and is more common in women than men. Diagnosis of Cushing's disease may involve blood tests, imaging studies, and a physical exam to evaluate cortisol levels and identify the presence of a pituitary adenoma. Treatment may involve surgery to remove the adenoma, radiation therapy, or medications to lower cortisol levels. It is essential to identify and manage Cushing's disease promptly to prevent complications such as osteoporosis, diabetes, and cardiovascular disease.\n",
            "The probable diagnosis is Cushing's syndrome, which is a disorder that occurs when the body is exposed to high levels of cortisol hormone for an extended period of time. In chronic smokers, Cushing's syndrome is often caused by the ectopic production of adrenocorticotropic hormone (ACTH) from a small cell lung cancer. Symptoms of Cushing's syndrome may include hypertension (high blood pressure), hyperglycemia (high blood sugar), weight gain, muscle weakness, and mood changes. The treatment for Cushing's syndrome depends on the underlying cause, and may include surgery, chemotherapy, radiation therapy, or medications to lower cortisol levels.\n",
            "Chronic excess levels of cortisol can lead to decreased levels of CRH and ACTH via negative feedback. When cortisol levels are high, they can bind to glucocorticoid receptors in the hypothalamus and pituitary gland, which inhibits the release of CRH and ACTH, respectively. This results in a decrease in the production and release of cortisol, which helps to maintain homeostasis in the body. However, chronic excess levels of cortisol can lead to a dysregulation of this feedback mechanism, which can have negative effects on various physiological processes. Therefore, it is important for individuals who have chronically elevated cortisol levels, such as those with Cushing's syndrome, to receive appropriate treatment to manage their condition and prevent further complications.\n",
            "The likely diagnosis is Cushing's syndrome, which is a condition that occurs when the body is exposed to high levels of the hormone cortisol for an extended period of time. In chronic smokers, Cushing's syndrome is often caused by an ectopic production of adrenocorticotropic hormone (ACTH) due to small cell lung carcinoma. Symptoms of Cushing's syndrome may include hypertension (high blood pressure), hyperglycemia (high blood sugar), weight gain, muscle weakness, and mood changes. Treatment for Cushing's syndrome may involve addressing the underlying cause, such as with surgery, chemotherapy, or radiation therapy for cancer, as well as medications to lower cortisol levels, such as ketoconazole or metyrapone.\n",
            "Lymphopenia may occur due to a high cortisol state, which induces apoptosis of lymphocytes. Lymphopenia is a condition characterized by a low level of lymphocytes, which are a type of white blood cell involved in the immune response. Cortisol is a hormone produced by the adrenal gland in response to stress. When cortisol levels are high, it can trigger programmed cell death, or apoptosis, of lymphocytes. This can lead to a decrease in their numbers and make individuals more susceptible to infections and other diseases. Lymphopenia can also be caused by other factors such as viral infections, autoimmune disorders, and certain medications.\n",
            "\n",
            "Q: What are the symptoms of high levels of cortisol?\n",
            "\n",
            "A: Cushing's syndrome is a rare disorder that occurs when the body is exposed to high levels of the hormone cortisol for an extended period of time.\n"
          ]
        }
      ],
      "source": [
        "# Try out the model with custom questions\n",
        "\n",
        "question = input(\"Ask a (medical related) question >>> \")  # e.g., \"What are the causes of asthma?\", \"What are the symptoms of high levels of cortisol?\", ...\n",
        "print()\n",
        "print(qa_pipeline(question))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}